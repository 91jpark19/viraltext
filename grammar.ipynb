{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32268ab-7b60-40ae-b812-3b9495d229f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.7.0-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bfc2d6a-72ce-4aa2-b750-4d5d1b8bb1a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.8/636.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /Users/2010y/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: joblib in /Users/2010y/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/2010y/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: click in /Users/2010y/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/2010y/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages (from nltk>=3.1->textblob) (2022.8.17)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18003046-86c0-4fbd-994d-e627e33063b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/2010y/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading config.json: 100%|██████████████████| 665/665 [00:00<00:00, 210kB/s]\n",
      "Downloading vocab.json: 100%|██████████████| 0.99M/0.99M [00:00<00:00, 5.42MB/s]\n",
      "Downloading merges.txt: 100%|████████████████| 446k/446k [00:00<00:00, 3.81MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.29M/1.29M [00:00<00:00, 5.90MB/s]\n",
      "/Users/2010y/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:998: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Downloading config.json: 100%|██████████████████| 762/762 [00:00<00:00, 183kB/s]\n",
      "Downloading pytorch_model.bin: 100%|█████████| 336M/336M [00:30<00:00, 11.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "import lmproof\n",
    "proof_reader = lmproof.load(\"en\")\n",
    "source = \"The foxes living on the Shire is brown.'\"\n",
    "corrected = ç # \"The foxes living in the Shire are brown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8ef0db-b991-4974-a321-7951b3e98ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The foxes living on the Shire are browning.'\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42a6ea00-c9f6-4def-bf19-17155924865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/2010y/opt/viraltext/raw-data/edgefield-no-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07743782-fa97-43eb-a61c-e77b3a5738df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in os.listdir():\n",
    "    if i.endswith('.txt'):\n",
    "        f = open(i, 'r')\n",
    "        lines = f.readlines()\n",
    "        mystr = ' '.join([line.strip() for line in lines])\n",
    "        with open('/Users/2010y/opt/viraltext/raw-data/edgefield-no-line/'+i, 'w+') as l:\n",
    "            l.write(mystr)\n",
    "            l.close()\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ad32102-d218-4021-b94e-78326f57a93d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef7e802a-e2cf-4303-a05b-21381d5bca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading vocab.txt: 100%|█████████████████| 208k/208k [00:00<00:00, 1.94MB/s]\n",
      "Downloading tokenizer_config.json: 100%|█████| 29.0/29.0 [00:00<00:00, 7.70kB/s]\n",
      "Downloading config.json: 100%|██████████████████| 570/570 [00:00<00:00, 166kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tz = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c078b09-be00-418f-8556-b3388586a435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'remains',\n",
       " 'characteristic',\n",
       " '##ally',\n",
       " 'confident',\n",
       " 'and',\n",
       " 'optimistic',\n",
       " '.',\n",
       " 'That',\n",
       " \"'\",\n",
       " 's',\n",
       " 'ne',\n",
       " '##gro',\n",
       " '##x']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"He remains characteristically confident and optimistic. That's negrox\"\n",
    "tz.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "954ab955-dd92-467a-88a6-2529c2b5f545",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No such file or directory (os error 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BpeTrainer\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m BpeTrainer(special_tokens\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[UNK]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[CLS]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SEP]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[MASK]\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwiki.train.raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwiki.valid.raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwiki.test.raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mException\u001b[0m: No such file or directory (os error 2)"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "\n",
    "tokenizer = Tokenizer(BPE())\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer.train(files=[\"wiki.train.raw\", \"wiki.valid.raw\", \"wiki.test.raw\"], trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2a81aa9-05d4-491e-ac5f-c97462c1ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f4a0553-a572-4469-b479-55d818511a01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'icu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Text\n\u001b[1;32m      4\u001b[0m blob \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWewillmeettoday.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m Text(blob)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages/polyglot/text.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequence, TextFile, TextFiles\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Detector, Language\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached_property\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Downloader\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages/polyglot/detect/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Detector, Language\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetector\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/viraltext/lib/python3.10/site-packages/polyglot/detect/base.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"Detecting languages\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01micu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Locale\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycld2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcld2\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'icu'"
     ]
    }
   ],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text\n",
    "\n",
    "blob = \"Wewillmeettoday.\"\n",
    "text = Text(blob)\n",
    "text.language = \"en\"\n",
    "print(text.morphemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18c04f-7943-450d-acd6-9f40a81b844b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f3067-50c6-467d-8f49-6691bb95a8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021ce07b-d488-464b-a33a-be8cba95f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"'Iriends of the Bank to adjora until next day i-i ordet to prnrre infrmta'ion.'\"\n",
    "corrected = proof_reader.proofread(source) # \"The foxes living in the Shire are brown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97386ff0-b24f-4c71-a56d-dcb27c2b6a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Iriends of the Bank to adjora until next day i-i order to prnrre infrmta'ion.'\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23f2a6c1-6afd-4525-8403-73503b75706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends\n",
      "order\n",
      "adore\n",
      "ii\n",
      "pierre\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "spell = SpellChecker()\n",
    "\n",
    "# find those words that may be misspelled\n",
    "string='Iriends of the Bank to adjora until next day i-i ordet to prnrre infrmta\\'ion.'\n",
    "misspelled = spell.unknown(tokenizer.tokenize(string))\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    # print(spell.candidates(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d332898-c45f-4475-93be-1a81c7c3ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friends\n",
      "order\n",
      "adore\n",
      "ii\n",
      "pierre\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in misspelled:\n",
    "    print(spell.correction(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64837ee8-060a-4342-b71e-6698139a73ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf02e3f-b9c7-49dc-b1dd-a66ee987db95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af48eb15-4c2b-4989-9dcd-613838bc0c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"infra'ion.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "TextBlob('infrmta\\'ion.').correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95f1d432-43bd-4c36-b6a2-1e3602090fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Password:\n",
      "sudo: a password is required\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ccfef-e061-41ca-af0b-e3f85109c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install jamspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b805ec8f-3e97-4943-990d-89f38d8efcfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jamspell'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjamspell\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Create a corrector\u001b[39;00m\n\u001b[1;32m      3\u001b[0m corrector \u001b[38;5;241m=\u001b[39m jamspell\u001b[38;5;241m.\u001b[39mTSpellCorrector()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jamspell'"
     ]
    }
   ],
   "source": [
    "import jamspell\n",
    "# Create a corrector\n",
    "corrector = jamspell.TSpellCorrector()\n",
    "\n",
    "# Load Language model -\n",
    "# argument is a downloaded model file path\n",
    "corrector.LoadLangModel('Downloads/en_model.bin')\n",
    "\n",
    "# To fix text automatically run FixFragment:\n",
    "print(corrector.FixFragment('Iriends of the Bank to adjora until next day i-i ordet to prnrre infrmta\\'ion.'))\n",
    "\n",
    "# To get a list of possible candidates\n",
    "# pass a splitted sentence, and a word position\n",
    "print(corrector.GetCandidates(['i', 'am', 'the', 'begt', 'spell', 'cherken'], 3))\n",
    "\n",
    "print(corrector.GetCandidates(['i', 'am', 'the', 'begt', 'spell', 'cherken'], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee458d-e9d3-4f35-a78f-a62bc3abe89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3beb50a-876d-4442-b272-e014002b25ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d63202-be41-4c43-95b6-f5b95c858f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GeeksforGeeks', 'is', 'for', 'geeks']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "     \n",
    "# Create a reference variable for Class WhitespaceTokenizer\n",
    "tk = WhitespaceTokenizer()\n",
    "     \n",
    "# Create a string input\n",
    "gfg = \"GeeksforGeeks \\nis\\t for geeks\"\n",
    "     \n",
    "# Use tokenize method\n",
    "geek = tk.tokenize(gfg)\n",
    "     \n",
    "print(geek)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
