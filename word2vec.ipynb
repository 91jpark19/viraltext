{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8a731-5026-4085-89a7-699e34538565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.models\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673fec8-ddc3-45ad-8af1-d75bb0a03715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0a242-46e5-4635-8666-70ca9791c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negro=pd.read_csv('levenstein_anti_slavery_bugle_window1_negro.csv')\n",
    "df_slave=pd.read_csv('levenstein_anti_slavery_bugle_window1_slave.csv')\n",
    "df_servant=pd.read_csv('levenstein_anti_slavery_bugle_window1_servant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb400eb-cbd2-4aa6-a07c-a95641228c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=[df_slave, df_servant]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c3f42-b6be-494e-9d11-ef81377695d8",
   "metadata": {},
   "source": [
    "pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b25436-875f-4668-b30b-4db2ba1606b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b4b5c-c177-4408-912c-019daa3a8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(dataframe:pd.DataFrame()):\n",
    "    dataframe['stopword']=dataframe['context'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    dataframe['punct']=dataframe['stopword'].str.replace('[^\\w\\s]', '')\n",
    "    dataframe['lower']=dataframe['punct'].str.lower()\n",
    "    dataframe['lemma']=dataframe['lower'].apply(lambda row:' '.join([w.lemma_ for w in nlp(row)]))\n",
    "    dataframe['token']=dataframe['lemma'].apply(word_tokenize)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5761c1-3a0d-476b-8e0f-c4663ea2d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df_lemma=lemmatization(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
